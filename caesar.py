#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CAESAR CIPHER CRACKER â€” ULTIMATE EDITION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ĞœĞ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ»Ñ Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€Ğ°ÑÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºĞ¸:
  1. Chi-squared Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°)
  2. Ğ‘Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²)
  3. Index of Coincidence (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ: Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ»Ğ¸ Ñ‚ĞµĞºÑÑ‚?)
  4. Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ Ğ¼Ğ¾Ñ€Ñ„Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³Ğ¾Ğ¼
  5. Ğ¡ĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞµ Ğ¾ĞºĞ½Ğ¾ Ğ´Ğ»Ñ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ñ… ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²
  6. ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ²ĞµÑĞ° Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ°
"""

import sys
import re
import math
import argparse
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Set
from dataclasses import dataclass, field
from functools import lru_cache
from collections import Counter

try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
    from rich import box
    from rich.prompt import Prompt, Confirm
    from rich.text import Text
    HAS_RICH = True
except ImportError:
    HAS_RICH = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ›Ğ˜ĞĞ“Ğ’Ğ˜Ğ¡Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞšĞĞĞ¡Ğ¢ĞĞĞ¢Ğ«
# Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° (Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞĞšĞ Ğ¯)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RU_ALPHA = 'Ğ°Ğ±Ğ²Ğ³Ğ´ĞµÑ‘Ğ¶Ğ·Ğ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑ‹ÑŒÑÑÑ'
RU_SET   = frozenset(RU_ALPHA)
RU_SIZE  = len(RU_ALPHA)  # 33

EN_ALPHA = 'abcdefghijklmnopqrstuvwxyz'
EN_SET   = frozenset(EN_ALPHA)
EN_SIZE  = len(EN_ALPHA)  # 26

# Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ±ÑƒĞºĞ² Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° (ĞĞšĞ Ğ¯)
RU_LETTER_FREQ = {
    'Ğ¾': 0.1097, 'Ğµ': 0.0845, 'Ğ°': 0.0801, 'Ğ¸': 0.0735, 'Ğ½': 0.0670,
    'Ñ‚': 0.0626, 'Ñ': 0.0547, 'Ñ€': 0.0473, 'Ğ²': 0.0454, 'Ğ»': 0.0440,
    'Ğº': 0.0349, 'Ğ¼': 0.0321, 'Ğ´': 0.0298, 'Ğ¿': 0.0281, 'Ñƒ': 0.0262,
    'Ñ': 0.0201, 'Ñ‹': 0.0190, 'ÑŒ': 0.0174, 'Ğ³': 0.0170, 'Ğ·': 0.0165,
    'Ğ±': 0.0159, 'Ñ‡': 0.0144, 'Ğ¹': 0.0121, 'Ñ…': 0.0097, 'Ğ¶': 0.0094,
    'Ñˆ': 0.0073, 'Ñ': 0.0064, 'Ñ†': 0.0048, 'Ñ‰': 0.0036, 'Ñ': 0.0032,
    'Ñ„': 0.0026, 'ÑŠ': 0.0004, 'Ñ‘': 0.0004,
}

# Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ±ÑƒĞºĞ² Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ° (Cornell)
EN_LETTER_FREQ = {
    'e': 0.1270, 't': 0.0906, 'a': 0.0817, 'o': 0.0751, 'i': 0.0697,
    'n': 0.0675, 's': 0.0633, 'h': 0.0609, 'r': 0.0599, 'd': 0.0425,
    'l': 0.0403, 'c': 0.0278, 'u': 0.0276, 'm': 0.0241, 'w': 0.0236,
    'f': 0.0223, 'g': 0.0202, 'y': 0.0197, 'p': 0.0193, 'b': 0.0129,
    'v': 0.0098, 'k': 0.0077, 'j': 0.0015, 'x': 0.0015, 'q': 0.0010,
    'z': 0.0007,
}

# Ğ¡Ğ°Ğ¼Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ñ‹Ğµ Ğ±Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹
RU_COMMON_BIGRAMS = frozenset({
    'ÑÑ‚', 'Ğ½Ğ¾', 'Ñ‚Ğ¾', 'Ğ½Ğ°', 'ĞµĞ½', 'Ğ½Ğ¸', 'ĞºĞ¾', 'Ñ€Ğ°', 'Ğ¾Ğ²', 'Ñ€Ğ¾',
    'Ğ¾Ñ', 'Ğ°Ğ»', 'ĞµÑ€', 'Ğ¾Ğ½', 'Ğ½Ğµ', 'Ğ»Ğ¸', 'Ğ¿Ğ¾', 'Ñ€Ğµ', 'Ğ¾Ñ€', 'Ğ°Ğ½',
    'Ğ¿Ñ€', 'ĞµÑ‚', 'Ğ¾Ğ»', 'Ñ‚Ğ°', 'ĞµĞ»', 'ĞºĞ°', 'Ğ²Ğ¾', 'Ñ‚Ğ¸', 'Ğ²Ğ°', 'Ğ¾Ğ´',
    'Ğ°Ñ‚', 'Ğ»Ğµ', 'Ğ¾Ñ‚', 'Ñ‚Ğµ', 'Ğ»Ğ°', 'Ğ¾Ğ¼', 'Ğ´Ğµ', 'ĞµÑ', 'Ğ²Ğµ', 'Ğ»Ğ¾',
    'Ğ¾Ğ³', 'Ğ·Ğ°', 'ÑĞº', 'Ñ‚ÑŒ', 'Ğ¸Ğ½', 'Ğ¸Ñ‚', 'Ğ¿Ğµ', 'ÑĞµ', 'Ğ¾Ğ±', 'Ğ´Ğ°',
    'ĞµĞ¼', 'Ğ³Ğ¾', 'Ğ°Ñ', 'Ğ¸Ğ·', 'Ğ¸Ğµ', 'Ñ€Ğ¸', 'Ğ¸Ğ»', 'ĞµĞ´', 'Ğ°Ñ€', 'Ğ°Ğ¼',
    'Ğ´Ğ¾', 'Ğ¸Ñ', 'Ñ‚Ñ€', 'Ğ½Ñ‹', 'Ğ¼Ğ¸', 'Ñ‡Ğ°', 'Ğ±Ğ¾', 'Ğ¾Ñ€', 'ĞµĞ³', 'Ñ€Ñƒ',
    'Ğ¼Ğµ', 'Ğ¼Ğ¾', 'Ğ³Ğ¸', 'Ğ´Ğ¸', 'Ğ²Ğ¸', 'Ğ±Ğµ', 'Ğ°Ğº', 'ĞºĞ¸', 'Ğ¾Ğµ', 'Ñ‘Ğ¼',
})

EN_COMMON_BIGRAMS = frozenset({
    'th', 'he', 'in', 'er', 'an', 're', 'on', 'at', 'en', 'nd',
    'ti', 'es', 'or', 'te', 'of', 'ed', 'is', 'it', 'al', 'ar',
    'st', 'to', 'nt', 'ng', 'se', 'ha', 'as', 'ou', 'io', 'le',
    've', 'co', 'me', 'de', 'hi', 'ri', 'ro', 'ic', 'ne', 'ea',
    'ra', 'ce', 'li', 'ch', 'll', 'be', 'ma', 'si', 'om', 'ur',
    'ca', 'el', 'ta', 'la', 'ns', 'ge', 'ha', 'ec', 'it', 'il',
    'pe', 'ol', 'no', 'na', 'us', 'di', 'wa', 'em', 'ac', 'ss',
})

# Ğ¡ÑƒÑ„Ñ„Ğ¸ĞºÑÑ‹ Ğ´Ğ»Ñ ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³Ğ°
RU_SUFFIXES = (
    'Ğ¾ÑÑ‚ÑŒ', 'ĞµĞ½Ğ¸Ğµ', 'Ğ°Ğ½Ğ¸Ğµ', 'Ñ‚ÑŒÑÑ', 'ÑÑ‚ÑÑ', 'Ğ¸Ñ‚ÑÑ', 'Ğ½Ğ¾Ğ³Ğ¾', 'Ğ½Ğ¾Ğ¼Ñƒ',
    'ÑĞºĞ¸Ğ¼', 'ÑĞºĞ¾Ğ¹', 'Ğ½Ñ‹Ñ…', 'Ğ½Ñ‹Ğµ', 'Ğ½Ñ‹Ğ¹', 'Ğ½Ğ°Ñ', 'Ğ½Ğ¾Ğµ', 'Ğ½Ğ¾Ğ¹',
    'Ğ¾Ğ³Ğ¾', 'Ğ¾Ğ¼Ñƒ', 'Ñ‹Ğ¼Ğ¸', 'Ğ°Ğ¼Ğ¸', 'ÑĞ¼Ğ¸', 'Ğ°Ñ‚ÑŒ', 'ÑÑ‚ÑŒ', 'ĞµÑ‚ÑŒ', 'Ğ¸Ñ‚ÑŒ',
    'ÑƒĞµÑ‚', 'Ğ°ĞµÑ‚', 'Ñ‘Ñ‚', 'ÑÑ‚', 'ÑƒÑ‚', 'Ğ¸Ñ‚', 'ĞµÑ‚',
    'Ğ¾Ğ²', 'ĞµĞ²', 'ĞµĞ¹', 'Ğ¸Ğ¹', 'Ñ‹Ğ¹', 'Ğ¾Ğ¹', 'Ğ°Ñ', 'Ğ¾Ğµ', 'Ğ¸Ğµ',
    'Ğ¾Ğ¼', 'ĞµĞ¼', 'Ğ°Ğ¼', 'ÑĞ¼', 'Ğ°Ñ…', 'ÑÑ…', 'Ñ‹Ñ…', 'Ğ¸Ñ…',
    'Ğ°Ğ»', 'Ğ¸Ğ»', 'ĞµĞ»', 'Ğ¾Ğ»', 'ÑƒĞ»',
    'Ñ‚ÑŒ', 'ÑÑ', 'ÑÑŒ',
)

EN_SUFFIXES = (
    'tion', 'ness', 'ment', 'able', 'ible', 'ious', 'eous',
    'ing', 'ous', 'ful', 'ive', 'ity', 'ent', 'ant', 'ion',
    'ism', 'ist', 'ory', 'ary', 'ery', 'ure', 'age', 'ise', 'ize',
    'ly', 'er', 'ed', 'es', 'al', 'en', 'ty',
    'or', 'ic', 'le',
    's',
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA CLASSES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(frozen=True)
class ShiftResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞ´Ğ²Ğ¸Ğ³Ğ°"""
    shift: int
    text: str
    chi_sq: float          # Chi-squared (Ğ¼ĞµĞ½ÑŒÑˆĞµ = Ğ»ÑƒÑ‡ÑˆĞµ)
    bigram_score: float    # Ğ‘Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° [0..1]
    dict_score: float      # Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° [0..1]
    stem_score: float      # Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³-Ğ¾Ñ†ĞµĞ½ĞºĞ° [0..1]
    combined: float        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° [0..1]
    matches: int           # Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€Ğ½Ñ‹Ñ… ÑĞ»Ğ¾Ğ²
    total_words: int       # Ğ’ÑĞµĞ³Ğ¾ ÑĞ»Ğ¾Ğ²

    @property
    def confidence(self) -> float:
        return min(self.combined * 100, 100.0)


@dataclass(frozen=True)
class Segment:
    """Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚ Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ´Ğ»Ñ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ¸Ñ„Ñ€Ğ°)"""
    text: str
    start: int
    end: int
    best_result: ShiftResult


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ›ĞĞ’ĞĞ Ğ¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_SCRIPT_DIR = Path(__file__).resolve().parent


class Dictionary:
    """Ğ¡Ğ¸Ğ½Ğ³Ğ»Ñ‚Ğ¾Ğ½-ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ñ Ğ»ĞµĞ½Ğ¸Ğ²Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¾Ğ¹ (Ñ€ÑƒÑÑĞºĞ¸Ğ¹ + Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹)"""
    _inst = None
    _ru_words: Optional[Set[str]] = None
    _en_words: Optional[Set[str]] = None

    def __new__(cls):
        if cls._inst is None:
            cls._inst = super().__new__(cls)
        return cls._inst

    @property
    def ru_words(self) -> Set[str]:
        if self._ru_words is None:
            self._load_ru()
        return self._ru_words

    @property
    def en_words(self) -> Set[str]:
        if self._en_words is None:
            self._load_en()
        return self._en_words

    def words(self, lang: str) -> Set[str]:
        return self.ru_words if lang == 'ru' else self.en_words

    @staticmethod
    def _find(name: str) -> Optional[Path]:
        """1. Ğ ÑĞ´Ğ¾Ğ¼ ÑĞ¾ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ¼  2. CWD  3. HOME"""
        for p in [_SCRIPT_DIR / name, Path(name), Path.home() / name]:
            if p.exists() and p.stat().st_size > 100:
                return p
        return None

    def _load_file(self, path: Path) -> Set[str]:
        try:
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                return {
                    w.lower() for line in f
                    if (w := line.strip()) and 2 <= len(w) <= 50 and w.isalpha()
                }
        except Exception:
            return set()

    def _load_ru(self):
        p = self._find('russian_dict.txt')
        self._ru_words = self._load_file(p) if p else set()
        self._ru_words |= {
            'Ğ¸', 'Ğ²', 'Ğ½Ğµ', 'Ğ½Ğ°', 'Ğ¾Ğ½', 'Ñ‡Ñ‚Ğ¾', 'ĞºĞ°Ğº', 'Ğ°', 'Ñ‚Ğ¾', 'Ğ²ÑĞµ',
            'Ğ¾Ğ½Ğ°', 'Ñ‚Ğ°Ğº', 'ĞµĞ³Ğ¾', 'Ğ½Ğ¾', 'Ğ´Ğ°', 'Ñ‚Ñ‹', 'Ğ¶Ğµ', 'Ğ²Ñ‹', 'Ğ·Ğ°', 'Ğ±Ñ‹',
            'Ğ¿Ğ¾', 'Ğ¾Ñ‚', 'Ğ¸Ğ·', 'Ğ´Ğ»Ñ', 'ÑÑ‚Ğ¾', 'Ğ¼Ñ‹', 'Ğ¾Ğ½Ğ¸', 'Ğ±Ñ‹Ğ»', 'Ğ±Ñ‹Ñ‚ÑŒ',
        }

    def _load_en(self):
        p = self._find('english_dict.txt')
        self._en_words = self._load_file(p) if p else set()
        self._en_words |= {
            'the', 'be', 'to', 'of', 'and', 'in', 'that', 'have', 'it', 'for',
            'not', 'on', 'with', 'he', 'as', 'you', 'do', 'at', 'this', 'but',
            'his', 'by', 'from', 'they', 'we', 'say', 'her', 'she', 'or', 'an',
            'will', 'my', 'one', 'all', 'would', 'there', 'their', 'what', 'so',
            'if', 'about', 'who', 'get', 'which', 'go', 'when', 'can', 'no',
        }

    def __len__(self) -> int:
        return len(self.ru_words) + len(self.en_words)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ”Ğ•Ğ¨Ğ˜Ğ¤Ğ ĞĞ’Ğ©Ğ˜Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Decryptor:
    """Ğ”ĞµÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· str.translate() â€” O(n), Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° C"""

    @staticmethod
    @lru_cache(maxsize=128)
    def _table(shift: int, lang: str) -> dict:
        alpha = RU_ALPHA if lang == 'ru' else EN_ALPHA
        size = len(alpha)
        lo = alpha
        up = lo.upper()
        s_lo = ''.join(lo[(i - shift) % size] for i in range(size))
        s_up = ''.join(up[(i - shift) % size] for i in range(size))
        return str.maketrans(lo + up, s_lo + s_up)

    @staticmethod
    def decrypt(text: str, shift: int, lang: str = 'ru') -> str:
        return text.translate(Decryptor._table(shift, lang))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡ĞšĞĞ Ğ•Ğ Ğ« (Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ñ†ĞµĞ½ĞºĞ¸)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def chi_squared(text: str, lang: str = 'ru') -> float:
    """
    Chi-squared Ñ‚ĞµÑÑ‚: ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ±ÑƒĞºĞ² Ñ ÑÑ‚Ğ°Ğ»Ğ¾Ğ½Ğ¾Ğ¼.
    ĞœĞµĞ½ÑŒÑˆĞµ = Ğ»ÑƒÑ‡ÑˆĞµ.
    """
    charset = RU_SET if lang == 'ru' else EN_SET
    freqs = RU_LETTER_FREQ if lang == 'ru' else EN_LETTER_FREQ

    letters = [c for c in text.lower() if c in charset]
    n = len(letters)
    if n == 0:
        return float('inf')

    observed = Counter(letters)
    chi_sq = 0.0
    for char, expected_freq in freqs.items():
        expected = expected_freq * n
        actual = observed.get(char, 0)
        if expected > 0:
            chi_sq += (actual - expected) ** 2 / expected

    return chi_sq


def bigram_score(text: str, lang: str = 'ru') -> float:
    """ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾ Ğ±Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°Ğ¼."""
    charset = RU_SET if lang == 'ru' else EN_SET
    common = RU_COMMON_BIGRAMS if lang == 'ru' else EN_COMMON_BIGRAMS

    letters = [c for c in text.lower() if c in charset]
    if len(letters) < 4:
        return 0.0

    bigrams = [letters[i] + letters[i+1] for i in range(len(letters) - 1)]
    if not bigrams:
        return 0.0

    hits = sum(1 for bg in bigrams if bg in common)
    return hits / len(bigrams)


def index_of_coincidence(text: str, lang: str = 'ru') -> float:
    """
    Index of Coincidence.
    RU â‰ˆ 0.0553, EN â‰ˆ 0.0667, random_ru â‰ˆ 0.0303, random_en â‰ˆ 0.0385
    """
    charset = RU_SET if lang == 'ru' else EN_SET

    letters = [c for c in text.lower() if c in charset]
    n = len(letters)
    if n < 2:
        return 0.0

    freq = Counter(letters)
    ic = sum(f * (f - 1) for f in freq.values()) / (n * (n - 1))
    return ic


def stem_word(word: str, lang: str = 'ru') -> str:
    """Ğ›Ñ‘Ğ³ĞºĞ¸Ğ¹ ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³: Ğ¾Ñ‚Ñ€ĞµĞ·Ğ°ĞµÑ‚ ÑÑƒÑ„Ñ„Ğ¸ĞºÑÑ‹."""
    suffixes = RU_SUFFIXES if lang == 'ru' else EN_SUFFIXES
    min_base = 2 if lang == 'en' else 3  # ĞĞ½Ğ³Ğ». Ğ¾ÑĞ½Ğ¾Ğ²Ñ‹ ĞºĞ¾Ñ€Ğ¾Ñ‡Ğµ
    for suffix in suffixes:
        if len(word) > len(suffix) + min_base and word.endswith(suffix):
            return word[:-len(suffix)]
    return word


def normalize_yo(text: str) -> str:
    """ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‘â†’Ğµ Ğ´Ğ»Ñ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾ÑÑ‚Ğ¸ Ğº Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ"""
    return text.replace('Ñ‘', 'Ğµ').replace('Ğ', 'Ğ•')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ›ĞĞ’ĞĞ ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_RU_WORD_RE = re.compile(r'[Ğ°-ÑÑ‘Ğ-Ğ¯Ğ]{2,}')
_EN_WORD_RE = re.compile(r'[a-zA-Z]{2,}')


def extract_words(text: str, lang: str = 'ru') -> Tuple[str, ...]:
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ° Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°"""
    pattern = _RU_WORD_RE if lang == 'ru' else _EN_WORD_RE
    return tuple(w.lower() for w in pattern.findall(text))


def dict_score(text: str, dictionary: Set[str], lang: str = 'ru') -> Tuple[float, int, int]:
    """
    Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ¼:
    1. Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
    2. Ğ‘ĞµĞ· Ñ‘ (Ğµ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ñ‘) [Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ RU]
    3. Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³ + Ğ¿Ğ¾Ğ¸ÑĞº
    """
    words = extract_words(text, lang)
    if not words:
        return 0.0, 0, 0

    matches = 0
    match_weight = 0
    total_weight = 0

    for word in words:
        wlen = len(word)
        total_weight += wlen

        # 1. Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
        if word in dictionary:
            matches += 1
            match_weight += wlen
            continue

        # 2. Ğ—Ğ°Ğ¼ĞµĞ½Ğ° Ñ‘â†’Ğµ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ RU)
        if lang == 'ru':
            word_no_yo = normalize_yo(word)
            if word_no_yo != word and word_no_yo in dictionary:
                matches += 1
                match_weight += wlen
                continue
        else:
            word_no_yo = word

        # 3. Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³
        stem = stem_word(word, lang)
        if stem != word and stem in dictionary:
            matches += 1
            match_weight += wlen * 0.8
            continue

        # 4. Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³ + Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        if lang == 'ru':
            stem_no_yo = stem_word(word_no_yo, lang)
            if stem_no_yo != word_no_yo and stem_no_yo in dictionary:
                matches += 1
                match_weight += wlen * 0.7
                continue

    ratio = matches / len(words) if words else 0.0
    weighted = match_weight / total_weight if total_weight > 0 else 0.0

    return ratio * 0.5 + weighted * 0.5, matches, len(words)


def stem_dict_score(text: str, dictionary: Set[str], lang: str = 'ru') -> float:
    """ĞĞ³Ñ€ĞµÑÑĞ¸Ğ²Ğ½Ñ‹Ğ¹ ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³: Ğ¾Ğ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ğ´Ğ¾ Ğ½Ğ°Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ĞºĞ¾Ñ€Ğ½Ñ."""
    words = extract_words(text, lang)
    if not words:
        return 0.0

    min_stem = 2 if lang == 'en' else 3
    hits = 0
    for word in words:
        stem = stem_word(normalize_yo(word) if lang == 'ru' else word, lang)
        candidate = stem
        while len(candidate) >= min_stem:
            if candidate in dictionary:
                hits += 1
                break
            candidate = candidate[:-1]

    return hits / len(words) if words else 0.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—ĞĞ¢ĞĞ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Analyzer:
    """
    ĞœĞ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ ÑĞ¾ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ²ĞµÑĞ°Ğ¼Ğ¸.
    
    Ğ”Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² (>50 Ğ±ÑƒĞºĞ²):
      â€” Chi-squared Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ (Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ½Ğ°Ğ´Ñ‘Ğ¶ĞµĞ½)
      â€” Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ğ°ĞµÑ‚
    
    Ğ”Ğ»Ñ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² (<20 Ğ±ÑƒĞºĞ²):
      â€” Ğ‘Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ ÑĞ¿Ğ°ÑĞ°ÑÑ‚
      â€” Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ + ÑÑ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹
      â€” Chi-squared Ğ½ĞµĞ½Ğ°Ğ´Ñ‘Ğ¶ĞµĞ½ (Ğ¼Ğ°Ğ»Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
    
    Ğ”Ğ»Ñ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ…:
      â€” Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ²ÑĞµÑ… Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
    """

    def __init__(self):
        self.dict = Dictionary()

    def detect_language(self, text: str) -> str:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑĞ·Ñ‹Ğº Ñ‚ĞµĞºÑÑ‚Ğ°"""
        ru = sum(1 for c in text.lower() if c in RU_SET)
        en = sum(1 for c in text.lower() if c in EN_SET)
        return 'ru' if ru > en else 'en'

    def _letter_count(self, text: str, lang: str = 'ru') -> int:
        charset = RU_SET if lang == 'ru' else EN_SET
        return sum(1 for c in text if c.lower() in charset)

    def analyze_shift(self, text: str, shift: int, lang: str = 'ru') -> ShiftResult:
        """ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ° ÑĞ´Ğ²Ğ¸Ğ³Ğ°"""
        decrypted = Decryptor.decrypt(text, shift, lang)
        dictionary = self.dict.words(lang)

        # 1. Chi-squared
        chi = chi_squared(decrypted, lang)

        # 2. Ğ‘Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹
        bg = bigram_score(decrypted, lang)

        # 3. Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ
        ds, matches, total = dict_score(decrypted, dictionary, lang)

        # 4. Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³
        ss = stem_dict_score(decrypted, dictionary, lang)

        # 5. ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ
        letter_count = self._letter_count(text, lang)
        combined = self._combine(chi, bg, ds, ss, letter_count)

        return ShiftResult(
            shift=shift,
            text=decrypted,
            chi_sq=chi,
            bigram_score=bg,
            dict_score=ds,
            stem_score=ss,
            combined=combined,
            matches=matches,
            total_words=total,
        )

    def _combine(
        self, chi: float, bg: float, ds: float, ss: float, n_letters: int
    ) -> float:
        """
        ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ ÑĞºĞ¾Ñ€Ğ¾Ğ².
        Ğ’ĞµÑĞ° Ğ¼ĞµĞ½ÑÑÑ‚ÑÑ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ°.
        """
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ chi-squared Ğ² [0..1] (Ğ¸Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼: Ğ¼ĞµĞ½ÑŒÑˆĞµ chi = Ğ»ÑƒÑ‡ÑˆĞµ)
        # Ğ¢Ğ¸Ğ¿Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½: 20-1000
        chi_norm = max(0.0, 1.0 - chi / 500.0)

        if n_letters >= 100:
            # Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: chi-squared Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ½Ğ°Ğ´Ñ‘Ğ¶ĞµĞ½
            w_chi, w_bg, w_dict, w_stem = 0.35, 0.10, 0.35, 0.20
        elif n_letters >= 30:
            # Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚: Ğ±Ğ°Ğ»Ğ°Ğ½Ñ
            w_chi, w_bg, w_dict, w_stem = 0.20, 0.20, 0.35, 0.25
        elif n_letters >= 10:
            # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚: Ğ±Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ¸ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ²Ğ°Ğ¶Ğ½ĞµĞµ
            w_chi, w_bg, w_dict, w_stem = 0.10, 0.30, 0.35, 0.25
        else:
            # ĞÑ‡ĞµĞ½ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹: Ğ±Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‚
            w_chi, w_bg, w_dict, w_stem = 0.05, 0.45, 0.30, 0.20

        return w_chi * chi_norm + w_bg * bg + w_dict * ds + w_stem * ss

    def crack(self, text: str, lang: str = None) -> List[ShiftResult]:
        """ĞŸĞµÑ€ĞµĞ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ²ÑĞµ ÑĞ´Ğ²Ğ¸Ğ³Ğ¸, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº"""
        if lang is None:
            lang = self.detect_language(text)
        alpha_size = RU_SIZE if lang == 'ru' else EN_SIZE
        results = [self.analyze_shift(text, s, lang) for s in range(alpha_size)]
        results.sort(key=lambda r: r.combined, reverse=True)
        return results

    def is_already_plaintext(self, text: str) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ ÑƒĞ¶Ğµ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¼"""
        lang = self.detect_language(text)
        dictionary = self.dict.words(lang)
        ds, matches, total = dict_score(text, dictionary, lang)

        if total > 0 and matches / total >= 0.7:
            return True

        if self._letter_count(text, lang) >= 30:
            ic = index_of_coincidence(text, lang)
            ic_threshold = 0.045 if lang == 'ru' else 0.055
            return ic > ic_threshold and ds > 0.4

        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ”Ğ•Ğ¢Ğ•ĞšĞ¢ĞĞ  Ğ¡ĞœĞ•Ğ¨ĞĞĞĞ«Ğ¥ Ğ¨Ğ˜Ğ¤Ğ ĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MixedDetector:
    """
    Ğ¡ĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞµ Ğ¾ĞºĞ½Ğ¾ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† ÑĞ¼ĞµĞ½Ñ‹ ĞºĞ»ÑÑ‡Ğ°.
    
    ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼:
    1. Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹ ĞºĞ»ÑÑ‡
    2. Ğ•ÑĞ»Ğ¸ confidence < Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ° â€” Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ³Ğ¸Ğ¿Ğ¾Ñ‚ĞµĞ·Ñƒ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑˆĞ¸Ñ„Ñ€Ğ°
    3. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞµ Ğ¾ĞºĞ½Ğ¾: Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼
       Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ Ğ´Ğ»Ñ Ğ¾ĞºÑ€ĞµÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
    4. ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ñ‡ĞºĞ¸ ÑĞ¼ĞµĞ½Ñ‹ ĞºĞ»ÑÑ‡Ğ° (Ğ³Ğ´Ğµ ĞºĞ»ÑÑ‡ Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ)
    5. Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ ÑÑ‚Ğ¸Ğ¼ Ñ‚Ğ¾Ñ‡ĞºĞ°Ğ¼
    6. Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° â€” Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
    """

    def __init__(self):
        self.analyzer = Analyzer()
        self.window_size = 40  # Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ² Ğ¾ĞºĞ½Ğµ

    def detect(self, text: str) -> List[Segment]:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸"""
        lang = self.analyzer.detect_language(text)
        charset = RU_SET if lang == 'ru' else EN_SET
        letters_only = [c for c in text if c.lower() in charset]
        n = len(letters_only)

        if n < self.window_size * 2:
            results = self.analyzer.crack(text, lang)
            best = results[0]
            return [Segment(text=best.text, start=0, end=len(text), best_result=best)]

        shift_map = self._compute_shift_map(text, lang)
        boundaries = self._find_boundaries(shift_map, text)

        segments = []
        for start, end in boundaries:
            segment_text = text[start:end]
            results = self.analyzer.crack(segment_text, lang)
            best = results[0]
            segments.append(Segment(
                text=best.text, start=start, end=end, best_result=best
            ))

        return segments

    def _compute_shift_map(self, text: str, lang: str = 'ru') -> List[int]:
        """Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ»ÑÑ‡ Ñ‡ĞµÑ€ĞµĞ· Ğ¾ĞºĞ½Ğ¾"""
        charset = RU_SET if lang == 'ru' else EN_SET
        alpha_size = RU_SIZE if lang == 'ru' else EN_SIZE
        n = len(text)
        shift_map = []
        half_w = self.window_size // 2

        for i in range(n):
            if text[i].lower() not in charset:
                shift_map.append(shift_map[-1] if shift_map else 0)
                continue

            start = max(0, i - half_w)
            end = min(n, i + half_w)
            window = text[start:end]

            best_shift = 0
            best_score = -1.0

            for s in range(alpha_size):
                dec = Decryptor.decrypt(window, s, lang)
                chi = chi_squared(dec, lang)
                bg = bigram_score(dec, lang)
                score = bg * 0.6 + max(0, 1 - chi / 500) * 0.4

                if score > best_score:
                    best_score = score
                    best_shift = s

            shift_map.append(best_shift)

        return shift_map

    def _find_boundaries(
        self, shift_map: List[int], text: str
    ) -> List[Tuple[int, int]]:
        """
        ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ°Ñ€Ñ‚Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ¾Ğ².
        Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ½ÑÑ‚Ğ²Ğ°.
        """
        n = len(shift_map)
        if n == 0:
            return [(0, len(text))]

        # Ğ¡Ğ³Ğ»Ğ°Ğ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ: Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¼Ğ¾Ğ´Ñƒ Ğ¾ĞºÑ€ĞµÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
        smooth_window = 15
        smoothed = []
        for i in range(n):
            start = max(0, i - smooth_window // 2)
            end = min(n, i + smooth_window // 2 + 1)
            neighborhood = shift_map[start:end]
            mode = Counter(neighborhood).most_common(1)[0][0]
            smoothed.append(mode)

        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ñ‡ĞºĞ¸ ÑĞ¼ĞµĞ½Ñ‹
        boundaries = []
        seg_start = 0
        current_shift = smoothed[0]

        for i in range(1, n):
            if smoothed[i] != current_shift:
                boundaries.append((seg_start, i))
                seg_start = i
                current_shift = smoothed[i]

        boundaries.append((seg_start, n))

        # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼: ÑĞ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ ÑĞ¾ÑĞµĞ´ÑĞ¼Ğ¸
        min_segment = 15
        merged = []
        for start, end in boundaries:
            if end - start < min_segment and merged:
                prev_start, _ = merged[-1]
                merged[-1] = (prev_start, end)
            else:
                merged.append((start, end))

        if not merged:
            return [(0, len(text))]

        # ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹: Ğ¸Ñ‰ĞµĞ¼ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»/Ğ·Ğ½Ğ°Ğº Ğ¿Ñ€ĞµĞ¿Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ
        adjusted = []
        for i, (start, end) in enumerate(merged):
            # ĞĞ°Ñ‡Ğ°Ğ»Ğ¾: ÑĞ´Ğ²Ğ¸Ğ³Ğ°ĞµĞ¼ Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»Ñƒ ÑĞ»Ğ¾Ğ²Ğ°
            if i > 0 and start > 0:
                # Ğ˜Ñ‰ĞµĞ¼ Ğ±Ğ»Ğ¸Ğ¶Ğ°Ğ¹ÑˆĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»/Ğ·Ğ½Ğ°Ğº Ğ½Ğ°Ğ·Ğ°Ğ´ (Ğ´Ğ¾ 5 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)
                for delta in range(min(5, start)):
                    if text[start - delta] in ' .,!?;:\n\t':
                        start = start - delta + 1
                        break
            # ĞšĞ¾Ğ½ĞµÑ†: ÑĞ´Ğ²Ğ¸Ğ³Ğ°ĞµĞ¼ Ğº ĞºĞ¾Ğ½Ñ†Ñƒ ÑĞ»Ğ¾Ğ²Ğ°
            if i < len(merged) - 1 and end < len(text):
                for delta in range(min(5, len(text) - end)):
                    if text[end + delta] in ' .,!?;:\n\t':
                        end = end + delta
                        break
            adjusted.append((start, end))

        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ñ
        final = [adjusted[0]]
        for start, end in adjusted[1:]:
            prev_start, prev_end = final[-1]
            if start < prev_end:
                start = prev_end
            if start < end:
                final.append((start, end))

        return final


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UI (Rich / Fallback)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class UI:
    def __init__(self):
        self.c = Console() if HAS_RICH else None

    def header(self):
        if self.c:
            self.c.print(Panel(
                "[bold cyan]CAESAR CRACKER â€” ULTIMATE EDITION[/bold cyan]\n"
                "[dim]ChiÂ² â€¢ Ğ‘Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ â€¢ Ğ¡Ñ‚ĞµĞ¼Ğ¼Ğ¸Ğ½Ğ³ â€¢ Ğ¡Ğ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğµ ÑˆĞ¸Ñ„Ñ€Ñ‹[/dim]",
                border_style="cyan", box=box.DOUBLE
            ))
            self.c.print()
        else:
            print("=" * 70)
            print("  CAESAR CRACKER â€” ULTIMATE EDITION")
            print("=" * 70)
            print()

    def info(self, dict_size: int, is_plain: bool, lang_name: str = ""):
        if self.c:
            status = "[green]âœ“ Ğ¢ĞµĞºÑÑ‚ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹ (Ğ½Ğµ Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½)[/green]" if is_plain else "[yellow]ğŸ” Ğ¢ĞµĞºÑÑ‚ Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½[/yellow]"
            self.c.print(Panel(
                f"ğŸ“– Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ: [bold]{dict_size:,}[/bold] ÑĞ»Ğ¾Ğ²\n"
                f"ğŸŒ Ğ¯Ğ·Ñ‹Ğº: [bold]{lang_name}[/bold]\n"
                f"ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {status}",
                title="[bold]ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ[/bold]", border_style="blue"
            ))
            self.c.print()
        else:
            status = "Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ğ¹" if is_plain else "Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½"
            print(f"Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ: {dict_size:,} ÑĞ»Ğ¾Ğ² | Ğ¯Ğ·Ñ‹Ğº: {lang_name} | Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {status}")
            print()

    def result_single(self, best: ShiftResult, top5: List[ShiftResult]):
        if self.c:
            # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ â€” Ğ±ĞµĞ· Ñ€Ğ°Ğ¼ĞºĞ¸, Ğ»ĞµĞ³ĞºĞ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ
            self.c.print()
            self.c.print("[bold green]ğŸ’¬ Ğ ĞĞ¡Ğ¨Ğ˜Ğ¤Ğ ĞĞ’ĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:[/bold green]")
            self.c.print()
            self.c.print(best.text)
            self.c.print()

            # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸
            self.c.print(
                f"[dim]ğŸ”‘ ĞšĞ»ÑÑ‡: [bold yellow]{best.shift}[/bold yellow]  "
                f"ğŸ“Š {self._conf_colored(best.confidence)}  "
                f"ğŸ“– {best.matches}/{best.total_words} ÑĞ»Ğ¾Ğ²  "
                f"ChiÂ²={best.chi_sq:.0f}  "
                f"Ğ‘Ğ¸Ğ³Ñ€.: {best.bigram_score:.0%}  "
                f"Ğ¡Ğ»Ğ¾Ğ².: {best.dict_score:.0%}  "
                f"Ğ¡Ñ‚ĞµĞ¼.: {best.stem_score:.0%}[/dim]"
            )
            self.c.print()

            # Ğ¢Ğ¾Ğ¿-5
            t5 = Table(
                box=box.SIMPLE, show_header=True,
                header_style="bold", title="[bold]ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ñ‹[/bold]"
            )
            t5.add_column("#", width=4)
            t5.add_column("ĞšĞ»ÑÑ‡", width=6)
            t5.add_column("Ğ”Ğ¾ÑÑ‚Ğ¾Ğ².", width=10)
            t5.add_column("Ğ¢ĞµĞºÑÑ‚")

            for i, r in enumerate(top5, 1):
                marker = "â­" if i == 1 else str(i)
                preview = r.text[:60] + "â€¦" if len(r.text) > 60 else r.text
                t5.add_row(marker, str(r.shift), self._conf_colored(r.confidence), preview)

            self.c.print(t5)
        else:
            print(f"\nğŸ’¬ Ğ ĞĞ¡Ğ¨Ğ˜Ğ¤Ğ ĞĞ’ĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:")
            print(best.text)
            print(f"\nğŸ”‘ ĞšĞ»ÑÑ‡: {best.shift}  Ğ”Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ: {best.confidence:.1f}%  "
                  f"Ğ¡Ğ»Ğ¾Ğ²: {best.matches}/{best.total_words}")
            print(f"ChiÂ²={best.chi_sq:.1f}  Ğ‘Ğ¸Ğ³Ñ€.={best.bigram_score:.0%}  "
                  f"Ğ¡Ğ»Ğ¾Ğ².={best.dict_score:.0%}  Ğ¡Ñ‚ĞµĞ¼.={best.stem_score:.0%}")
            print("\nĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ñ‹:")
            for i, r in enumerate(top5, 1):
                m = "â­" if i == 1 else f"{i}."
                p = r.text[:60] + "â€¦" if len(r.text) > 60 else r.text
                print(f"  {m} ĞºĞ»ÑÑ‡={r.shift} ({r.confidence:.0f}%) {p}")

    def result_mixed(self, segments: List[Segment]):
        keys = [s.best_result.shift for s in segments]
        is_mixed = len(set(keys)) > 1

        full_text = ''.join(s.text for s in segments)
        avg_conf = sum(s.best_result.confidence for s in segments) / len(segments)

        if self.c:
            if is_mixed:
                self.c.print(Panel(
                    f"[bold yellow]âš ï¸  Ğ¡ĞœĞ•Ğ¨ĞĞĞĞ«Ğ™ Ğ¨Ğ˜Ğ¤Ğ : {len(set(keys))} Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ĞºĞ»ÑÑ‡ĞµĞ¹[/bold yellow]\n"
                    f"ĞšĞ»ÑÑ‡Ğ¸: [bold]{', '.join(str(k) for k in keys)}[/bold]",
                    border_style="yellow", box=box.HEAVY
                ))
                self.c.print()

            tbl = Table(
                box=box.ROUNDED, show_header=True,
                header_style="bold magenta", title="[bold]Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹[/bold]"
            )
            tbl.add_column("#", width=4, style="cyan")
            tbl.add_column("ĞšĞ»ÑÑ‡", width=6, style="yellow")
            tbl.add_column("Ğ”Ğ¾ÑÑ‚Ğ¾Ğ².", width=10)
            tbl.add_column("Ğ¡Ğ»Ğ¾Ğ²Ğ°", width=8, style="blue")
            tbl.add_column("Ğ¢ĞµĞºÑÑ‚")

            for i, seg in enumerate(segments, 1):
                r = seg.best_result
                preview = seg.text[:50] + "â€¦" if len(seg.text) > 50 else seg.text
                tbl.add_row(
                    str(i), str(r.shift),
                    self._conf_colored(r.confidence),
                    f"{r.matches}/{r.total_words}",
                    preview
                )

            self.c.print(tbl)
            self.c.print()

            self.c.print("[bold green]ğŸ’¬ ĞŸĞĞ›ĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢:[/bold green]")
            self.c.print()
            self.c.print(full_text)
            self.c.print()
        else:
            if is_mixed:
                print(f"\nâš ï¸  Ğ¡ĞœĞ•Ğ¨ĞĞĞĞ«Ğ™ Ğ¨Ğ˜Ğ¤Ğ : ĞºĞ»ÑÑ‡Ğ¸ {keys}")
            for i, seg in enumerate(segments, 1):
                r = seg.best_result
                print(f"  Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚ {i}: ĞºĞ»ÑÑ‡={r.shift} ({r.confidence:.0f}%) {seg.text[:60]}")
            print(f"\nĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ ({avg_conf:.0f}%):\n{full_text}")

    def _conf_colored(self, conf: float) -> str:
        if not self.c:
            return f"{conf:.1f}%"
        if conf >= 80:
            return f"[bold green]{conf:.1f}%[/bold green]"
        elif conf >= 50:
            return f"[yellow]{conf:.1f}%[/yellow]"
        else:
            return f"[red]{conf:.1f}%[/red]"

    def ask_multiline(self, prompt: str) -> str:
        """ĞœĞ½Ğ¾Ğ³Ğ¾ÑÑ‚Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ²Ğ²Ğ¾Ğ´: Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° Ğ¸Ğ»Ğ¸ Ctrl+D Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°ĞµÑ‚"""
        if self.c:
            self.c.print(f"[bold yellow]{prompt}[/bold yellow]")
            self.c.print("[dim](Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° = ĞºĞ¾Ğ½ĞµÑ† Ğ²Ğ²Ğ¾Ğ´Ğ°)[/dim]")
        else:
            print(f"{prompt}")
            print("(Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ° = ĞºĞ¾Ğ½ĞµÑ† Ğ²Ğ²Ğ¾Ğ´Ğ°)")

        lines = []
        try:
            while True:
                line = input()
                if line == '':
                    break
                lines.append(line)
        except EOFError:
            pass
        return '\n'.join(lines)

    def confirm(self, question: str) -> bool:
        if self.c:
            return Confirm.ask(f"[bold]{question}[/bold]")
        return input(f"{question} (y/n): ").strip().lower() in ('y', 'Ğ´', 'Ğ´Ğ°')


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞ Ğ˜Ğ›ĞĞ–Ğ•ĞĞ˜Ğ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(
        prog='caesar',
        description='Caesar Cipher Cracker â€” Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ´ĞµÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²ĞºĞ° ÑˆĞ¸Ñ„Ñ€Ğ° Ğ¦ĞµĞ·Ğ°Ñ€Ñ',
    )
    p.add_argument('text', nargs='*', help='Ğ—Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚')
    p.add_argument('-r', '--raw', action='store_true',
                   help='Ğ’Ñ‹Ğ²ĞµÑÑ‚Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ€Ğ°ÑÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (ÑƒĞ´Ğ¾Ğ±Ğ½Ğ¾ Ğ´Ğ»Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ pipe)')
    p.add_argument('-m', '--mixed', action='store_true',
                   help='ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆĞ¸Ñ„Ñ€')
    p.add_argument('-l', '--lang', choices=['ru', 'en'],
                   help='ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‚ÑŒ ÑĞ·Ñ‹Ğº (Ğ¸Ğ½Ğ°Ñ‡Ğµ Ğ°Ğ²Ñ‚Ğ¾)')
    return p.parse_args()


def run():
    args = parse_args()
    raw = args.raw

    analyzer = Analyzer()
    detector = MixedDetector()

    # Ğ’Ğ²Ğ¾Ğ´ Ñ‚ĞµĞºÑÑ‚Ğ°
    if args.text:
        text = ' '.join(args.text)
        auto = True
    elif not sys.stdin.isatty():
        text = sys.stdin.read().strip()
        auto = True
    else:
        if raw:
            print("ĞÑˆĞ¸Ğ±ĞºĞ°: Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ --raw Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ¸Ğ»Ğ¸ Ñ‡ĞµÑ€ĞµĞ· pipe", file=sys.stderr)
            sys.exit(1)
        ui = UI()
        ui.header()
        text = ui.ask_multiline("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚:")
        auto = False

    if not text or text.lower() in ('exit', 'quit', 'q'):
        return

    lang = args.lang or analyzer.detect_language(text)

    # --- RAW MODE: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµĞºÑÑ‚ ---
    if raw:
        results = analyzer.crack(text, lang)
        best = results[0]
        if best.confidence < 60 and len(text) > 60:
            segments = detector.detect(text)
            keys = set(s.best_result.shift for s in segments)
            if len(keys) > 1:
                print(''.join(s.text for s in segments))
                return
        print(best.text)
        return

    # --- FULL UI MODE ---
    if auto:
        ui = UI()
        ui.header()

    lang_name = "Ğ ÑƒÑÑĞºĞ¸Ğ¹" if lang == 'ru' else "English"
    is_plain = analyzer.is_already_plaintext(text)
    ui.info(len(analyzer.dict), is_plain, lang_name)

    if is_plain:
        if auto:
            results = analyzer.crack(text, lang)
            ui.result_single(results[0], results[:5])
            return
        else:
            proceed = ui.confirm("Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ Ğ½Ğ° Ğ½ĞµĞ·Ğ°ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹. ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ?")
            if not proceed:
                return

    results = analyzer.crack(text, lang)
    best = results[0]

    use_mixed = args.mixed
    if not use_mixed and best.confidence < 60 and len(text) > 60:
        if auto:
            use_mixed = True
        else:
            use_mixed = ui.confirm(
                f"Ğ”Ğ¾ÑÑ‚Ğ¾Ğ²ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ¸Ğ·ĞºĞ°Ñ ({best.confidence:.0f}%). ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆĞ¸Ñ„Ñ€?"
            )

    if not use_mixed and not auto:
        use_mixed = ui.confirm("ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ ÑĞ¼ĞµÑˆĞ°Ğ½Ğ½Ñ‹Ğ¹ ÑˆĞ¸Ñ„Ñ€ (Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ ĞºĞ»ÑÑ‡Ğ¸)?")

    if use_mixed:
        segments = detector.detect(text)
        keys = set(s.best_result.shift for s in segments)

        if len(keys) > 1:
            ui.result_mixed(segments)
        else:
            ui.result_single(best, results[:5])
    else:
        ui.result_single(best, results[:5])


if __name__ == '__main__':
    try:
        run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹")
    except Exception as e:
        print(f"\nâŒ {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)
